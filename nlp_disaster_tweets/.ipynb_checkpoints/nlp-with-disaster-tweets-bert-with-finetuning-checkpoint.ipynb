{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-11T08:12:41.131069Z",
     "iopub.status.busy": "2023-02-11T08:12:41.130576Z",
     "iopub.status.idle": "2023-02-11T08:12:41.166916Z",
     "shell.execute_reply": "2023-02-11T08:12:41.165857Z",
     "shell.execute_reply.started": "2023-02-11T08:12:41.131027Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:12:41.174139Z",
     "iopub.status.busy": "2023-02-11T08:12:41.169583Z",
     "iopub.status.idle": "2023-02-11T08:13:05.264521Z",
     "shell.execute_reply": "2023-02-11T08:13:05.263331Z",
     "shell.execute_reply.started": "2023-02-11T08:12:41.174101Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "#import gc\n",
    "import re\n",
    "import string\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "SEED = 1337\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline,BertTokenizer \n",
    "from bs4 import BeautifulSoup\n",
    "!pip install contractions\n",
    "import contractions\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:13:05.268008Z",
     "iopub.status.busy": "2023-02-11T08:13:05.266677Z",
     "iopub.status.idle": "2023-02-11T08:13:05.278074Z",
     "shell.execute_reply": "2023-02-11T08:13:05.275874Z",
     "shell.execute_reply.started": "2023-02-11T08:13:05.267954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\OneDrive\\Documents\\Kaggle\n",
      "C:\\Users\\jethr\\OneDrive\\Documents\\Kaggle\\input\n"
     ]
    }
   ],
   "source": [
    "PARENT_DIR = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "INPUT_DIR = os.path.join(PARENT_DIR,\"input\")\n",
    "TRAIN_CSV = os.path.join(INPUT_DIR,\"train.csv\")\n",
    "TEST_CSV = os.path.join(INPUT_DIR,\"test.csv\")\n",
    "print(PARENT_DIR)\n",
    "print(INPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:14:41.119934Z",
     "iopub.status.busy": "2023-02-11T08:14:41.118900Z",
     "iopub.status.idle": "2023-02-11T08:14:41.162384Z",
     "shell.execute_reply": "2023-02-11T08:14:41.161238Z",
     "shell.execute_reply.started": "2023-02-11T08:14:41.119886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape = (7613, 5)\n",
      "Training Set Memory Usage = 0.20 MB\n",
      "Test Set Shape = (3263, 4)\n",
      "Test Set Memory Usage = 0.08 MB\n"
     ]
    }
   ],
   "source": [
    "train_csv = pd.read_csv(r\"C:\\Users\\jethr\\OneDrive\\Documents\\Kaggle\\NLPTweets\\input\\train.csv\", dtype={'id': np.int16, 'target': np.int8})\n",
    "test_csv = pd.read_csv(r\"C:\\Users\\jethr\\OneDrive\\Documents\\Kaggle\\NLPTweets\\input\\test.csv\", dtype={'id': np.int16})\n",
    "df_train = pd.DataFrame(train_csv)\n",
    "df_test = pd.DataFrame(test_csv)\n",
    "\n",
    "\n",
    "print('Training Set Shape = {}'.format(df_train.shape))\n",
    "print('Training Set Memory Usage = {:.2f} MB'.format(df_train.memory_usage().sum() / 1024**2))\n",
    "print('Test Set Shape = {}'.format(df_test.shape))\n",
    "print('Test Set Memory Usage = {:.2f} MB'.format(df_test.memory_usage().sum() / 1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:14:42.884664Z",
     "iopub.status.busy": "2023-02-11T08:14:42.884113Z",
     "iopub.status.idle": "2023-02-11T08:14:43.872316Z",
     "shell.execute_reply": "2023-02-11T08:14:43.871318Z",
     "shell.execute_reply.started": "2023-02-11T08:14:42.884629Z"
    }
   },
   "outputs": [],
   "source": [
    "#understanding metadata\n",
    "df_train['word_count'] = df_train['text'].apply(lambda x: len(str(x).split()))\n",
    "df_test['word_count'] = df_test['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# unique_word_count\n",
    "df_train['unique_word_count'] = df_train['text'].apply(lambda x: len(set(str(x).split())))\n",
    "df_test['unique_word_count'] = df_test['text'].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# stop_word_count\n",
    "df_train['stop_word_count'] = df_train['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "df_test['stop_word_count'] = df_test['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "\n",
    "# url_count\n",
    "df_train['url_count'] = df_train['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "df_test['url_count'] = df_test['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "\n",
    "# mean_word_length\n",
    "df_train['mean_word_length'] = df_train['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "df_test['mean_word_length'] = df_test['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "# char_count\n",
    "df_train['char_count'] = df_train['text'].apply(lambda x: len(str(x)))\n",
    "df_test['char_count'] = df_test['text'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# punctuation_count\n",
    "df_train['punctuation_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "df_test['punctuation_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "# hashtag_count\n",
    "df_train['hashtag_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "df_test['hashtag_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "\n",
    "# mention_count\n",
    "df_train['mention_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
    "df_test['mention_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
    "df_train['word_count'] = df_train['text'].apply(lambda x: len(str(x).split()))\n",
    "df_test['word_count'] = df_test['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# unique_word_count\n",
    "df_train['unique_word_count'] = df_train['text'].apply(lambda x: len(set(str(x).split())))\n",
    "df_test['unique_word_count'] = df_test['text'].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# stop_word_count\n",
    "df_train['stop_word_count'] = df_train['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "df_test['stop_word_count'] = df_test['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\n",
    "\n",
    "# url_count\n",
    "df_train['url_count'] = df_train['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "df_test['url_count'] = df_test['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "\n",
    "# mean_word_length\n",
    "df_train['mean_word_length'] = df_train['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "df_test['mean_word_length'] = df_test['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "# char_count\n",
    "df_train['char_count'] = df_train['text'].apply(lambda x: len(str(x)))\n",
    "df_test['char_count'] = df_test['text'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# punctuation_count\n",
    "df_train['punctuation_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "df_test['punctuation_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "# hashtag_count\n",
    "df_train['hashtag_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "df_test['hashtag_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "\n",
    "# mention_count\n",
    "df_train['mention_count'] = df_train['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
    "df_test['mention_count'] = df_test['text'].apply(lambda x: len([c for c in str(x) if c == '@']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring to [Gunes Evitan's Notebook](https://www.kaggle.com/code/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert) and [Rohit Gurad's Notebook](https://www.kaggle.com/code/rohitgarud/all-almost-data-preprocessing-techniques-for-nlp) on data cleaning & practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:14:43.936703Z",
     "iopub.status.busy": "2023-02-11T08:14:43.936308Z",
     "iopub.status.idle": "2023-02-11T08:14:43.943517Z",
     "shell.execute_reply": "2023-02-11T08:14:43.942181Z",
     "shell.execute_reply.started": "2023-02-11T08:14:43.936670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jethr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jethr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Set-up Lemmatization\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = [lemmatizer.lemmatize(word) for word in text.split()]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:14:44.095637Z",
     "iopub.status.busy": "2023-02-11T08:14:44.094934Z",
     "iopub.status.idle": "2023-02-11T08:14:59.869248Z",
     "shell.execute_reply": "2023-02-11T08:14:59.868029Z",
     "shell.execute_reply.started": "2023-02-11T08:14:44.095600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: symspellpy in c:\\users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages (6.7.7)\n",
      "Requirement already satisfied: editdistpy>=0.1.3 in c:\\users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages (from symspellpy) (0.1.3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up word correction\n",
    "!pip install symspellpy\n",
    "import pkg_resources\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "\n",
    "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\"\n",
    ")\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:14:59.871970Z",
     "iopub.status.busy": "2023-02-11T08:14:59.871537Z",
     "iopub.status.idle": "2023-02-11T08:14:59.879549Z",
     "shell.execute_reply": "2023-02-11T08:14:59.878531Z",
     "shell.execute_reply.started": "2023-02-11T08:14:59.871919Z"
    }
   },
   "outputs": [],
   "source": [
    "def correct_spelling_symspell(text):\n",
    "    words = [\n",
    "        sym_spell.lookup(\n",
    "            word, \n",
    "            Verbosity.CLOSEST, \n",
    "            max_edit_distance=2,\n",
    "            include_unknown=True\n",
    "            )[0].term \n",
    "        for word in text.split()] \n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:14:59.881698Z",
     "iopub.status.busy": "2023-02-11T08:14:59.881163Z",
     "iopub.status.idle": "2023-02-11T08:15:00.237011Z",
     "shell.execute_reply": "2023-02-11T08:15:00.236124Z",
     "shell.execute_reply.started": "2023-02-11T08:14:59.881653Z"
    }
   },
   "outputs": [],
   "source": [
    "#correctin compouund words\n",
    "bigram_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\"\n",
    ")\n",
    "sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "\n",
    "def correct_spelling_symspell_compound(text):\n",
    "    words = [\n",
    "        sym_spell.lookup_compound(\n",
    "            word, \n",
    "            max_edit_distance=2\n",
    "            )[0].term \n",
    "        for word in text.split()] \n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:15:00.240209Z",
     "iopub.status.busy": "2023-02-11T08:15:00.239807Z",
     "iopub.status.idle": "2023-02-11T08:15:00.253123Z",
     "shell.execute_reply": "2023-02-11T08:15:00.251947Z",
     "shell.execute_reply.started": "2023-02-11T08:15:00.240173Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    #fill NA\n",
    "    data[\"keyword\"] = data[\"keyword\"].fillna(\"\")\n",
    "    data[\"location\"] = data[\"location\"].fillna(\"\")\n",
    "    #combine keyword with text\n",
    "    data[\"tweet\"] = data[\"keyword\"] + \" \" + data[\"text\"]\n",
    "    #lower case\n",
    "    data[\"tweet\"] = data[\"tweet\"].str.lower()\n",
    "    #remove HTML\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "    #expand contractions\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(contractions.fix)\n",
    "    #remove URLs\n",
    "    url_pattern = re.compile(r'https?://(www\\.)?(\\w+)(\\.\\w+)(/\\w*)?')\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: re.sub(url_pattern,\"\",x))\n",
    "    #remove emails\n",
    "    email_pattern = re.compile(r\"[\\w\\.-]+@[\\w\\.-]+\\.\\w+\")\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: re.sub(email_pattern,\"\",x))\n",
    "    #remove tweet mentions\n",
    "    mention_pattern = re.compile(r\"@\\w+\")\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: re.sub(mention_pattern,\"\",x))\n",
    "    #remove punctuations, keeping hashtags to tokenize\n",
    "    punc_clean = string.punctuation.replace(\"#\",\"\")\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: re.sub('[%s]' % re.escape(punc_clean), \" \",x))\n",
    "    #remove digits\n",
    "    digit_pattern = re.compile(\"\\w*\\d+\\w*\")\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: re.sub(digit_pattern,\"\",x))  \n",
    "    #remove extra space\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: re.sub(' +', ' ', x).strip())\n",
    "    #lemmatize\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lemmatize_text)\n",
    "    #clean spelling correction\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(correct_spelling_symspell)\n",
    "    #remove compound\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(correct_spelling_symspell_compound)\n",
    "    #remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    data[\"tweet\"] = data[\"tweet\"].apply(lambda x: \" \".join([word for word in str(x).split() if word not in stop_words]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:15:00.255259Z",
     "iopub.status.busy": "2023-02-11T08:15:00.254528Z",
     "iopub.status.idle": "2023-02-11T08:15:17.814492Z",
     "shell.execute_reply": "2023-02-11T08:15:17.813502Z",
     "shell.execute_reply.started": "2023-02-11T08:15:00.255223Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#cleaning data\n",
    "df_train = clean_data(df_train)\n",
    "df_test = clean_data(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:22:27.059627Z",
     "iopub.status.busy": "2023-02-11T08:22:27.058858Z",
     "iopub.status.idle": "2023-02-11T08:22:27.073676Z",
     "shell.execute_reply": "2023-02-11T08:22:27.071413Z",
     "shell.execute_reply.started": "2023-02-11T08:22:27.059584Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating CustomDataset Class\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, max_len,data_type):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.tweet = dataframe.tweet\n",
    "        self.word_count = dataframe.word_count\n",
    "        self.unique_word_count = dataframe.unique_word_count\n",
    "        self.stop_word_count = dataframe.stop_word_count\n",
    "        self.mean_word_length = dataframe.mean_word_length\n",
    "        self.char_count = dataframe.char_count\n",
    "        self.punctuation_count = dataframe.punctuation_count\n",
    "        self.max_len = max_len\n",
    "        self.data_type = data_type\n",
    "        \n",
    "        if data_type == \"train\":\n",
    "            self.targets = dataframe.target\n",
    "            self.data_type = data_type\n",
    "        else:\n",
    "            self.targets = \"\"\n",
    "            self.data_type = \"test\"\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweet)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        tweet = str(self.tweet[index])\n",
    "        tweet = \" \".join(tweet.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            tweet,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        if self.data_type == \"train\":\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "                'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'ids': torch.tensor(ids, dtype=torch.long),\n",
    "                'mask': torch.tensor(mask, dtype=torch.long),\n",
    "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:16:39.875699Z",
     "iopub.status.busy": "2023-02-11T08:16:39.875267Z",
     "iopub.status.idle": "2023-02-11T08:16:44.088849Z",
     "shell.execute_reply": "2023-02-11T08:16:44.087451Z",
     "shell.execute_reply.started": "2023-02-11T08:16:39.875651Z"
    }
   },
   "outputs": [],
   "source": [
    "#load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:23:47.898046Z",
     "iopub.status.busy": "2023-02-11T08:23:47.897536Z",
     "iopub.status.idle": "2023-02-11T08:23:47.908382Z",
     "shell.execute_reply": "2023-02-11T08:23:47.906860Z",
     "shell.execute_reply.started": "2023-02-11T08:23:47.898004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (7613, 15)\n",
      "TRAIN Dataset: (6090, 15)\n",
      "TEST Dataset: (1523, 15)\n"
     ]
    }
   ],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 100\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "\n",
    "# Creating the dataset and dataloader for the neural network\n",
    "train_size = 0.8\n",
    "train_dataset=df_train.sample(frac=train_size,random_state=200)\n",
    "dev_dataset=df_train.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df_train.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(dev_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN,\"train\")\n",
    "testing_set = CustomDataset(dev_dataset, tokenizer, MAX_LEN,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:23:48.627072Z",
     "iopub.status.busy": "2023-02-11T08:23:48.626614Z",
     "iopub.status.idle": "2023-02-11T08:23:48.633551Z",
     "shell.execute_reply": "2023-02-11T08:23:48.632237Z",
     "shell.execute_reply.started": "2023-02-11T08:23:48.627038Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load in batch parameters\n",
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:23:49.185695Z",
     "iopub.status.busy": "2023-02-11T08:23:49.185023Z",
     "iopub.status.idle": "2023-02-11T08:23:51.806387Z",
     "shell.execute_reply": "2023-02-11T08:23:51.805243Z",
     "shell.execute_reply.started": "2023-02-11T08:23:49.185657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\jethr\\AppData\\Local\\Temp\\ipykernel_24976\\3195988680.py:13: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.l3.weight)\n",
      "C:\\Users\\jethr\\AppData\\Local\\Temp\\ipykernel_24976\\3195988680.py:14: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.l4.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Dropout(p=0.3, inplace=False)\n",
       "  (l3): Linear(in_features=768, out_features=20, bias=True)\n",
       "  (l4): Linear(in_features=20, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = transformers.BertModel.from_pretrained('bert-base-uncased',return_dict=False)\n",
    "        #self.l1 = BertForSequenceClassification.from_pretrained('bert-large-uncased',num_labels = 2,output_attentions = False,output_hidden_states = False)\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, 20)\n",
    "        self.l4 = torch.nn.Linear(20,1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        torch.nn.init.xavier_uniform(self.l3.weight)\n",
    "        torch.nn.init.xavier_uniform(self.l4.weight)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output_1= self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
    "        output_2 = self.l2(output_1)\n",
    "        output_3 = self.l3(output_2)\n",
    "        output_4 = self.relu(output_3)\n",
    "        output_s = self.l4(output_4)\n",
    "        output = self.sigmoid(output_s)\n",
    "        return output\n",
    "    \n",
    "\n",
    "model = BERTClass()\n",
    "model.to(torch.device('cuda:0')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:21:37.042434Z",
     "iopub.status.busy": "2023-02-11T08:21:37.042016Z",
     "iopub.status.idle": "2023-02-11T08:21:37.047647Z",
     "shell.execute_reply": "2023-02-11T08:21:37.046597Z",
     "shell.execute_reply.started": "2023-02-11T08:21:37.042395Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:21:37.050181Z",
     "iopub.status.busy": "2023-02-11T08:21:37.049663Z",
     "iopub.status.idle": "2023-02-11T08:21:37.058700Z",
     "shell.execute_reply": "2023-02-11T08:21:37.057606Z",
     "shell.execute_reply.started": "2023-02-11T08:21:37.050128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)\n",
    "#optimizer = torch.optim.SGD(params =  model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = LEARNING_RATE, # args.learning_rate\n",
    "                  eps = 1e-8 # args.adam_epsilon\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "train_history = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:24:45.292141Z",
     "iopub.status.busy": "2023-02-11T08:24:45.291663Z",
     "iopub.status.idle": "2023-02-11T08:24:45.303843Z",
     "shell.execute_reply": "2023-02-11T08:24:45.301997Z",
     "shell.execute_reply.started": "2023-02-11T08:24:45.292100Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    batch = 0\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = loss_fn(outputs[:,0], targets)\n",
    "        if _%10==0:\n",
    "            batch +=1\n",
    "            train_history[batch] = loss.item()\n",
    "            train_history[epoch] = loss.item()\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "439132672"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T08:24:45.497833Z",
     "iopub.status.busy": "2023-02-11T08:24:45.496823Z",
     "iopub.status.idle": "2023-02-11T08:30:46.747772Z",
     "shell.execute_reply": "2023-02-11T08:30:46.746239Z",
     "shell.execute_reply.started": "2023-02-11T08:24:45.497797Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  0.8733754754066467\n",
      "Epoch: 0, Loss:  0.7449067234992981\n",
      "Epoch: 0, Loss:  0.8457844257354736\n",
      "Epoch: 0, Loss:  0.8159424066543579\n",
      "Epoch: 0, Loss:  0.7503937482833862\n",
      "Epoch: 0, Loss:  0.7831188440322876\n",
      "Epoch: 0, Loss:  0.7617174386978149\n",
      "Epoch: 0, Loss:  0.6707155108451843\n",
      "Epoch: 0, Loss:  0.7294549942016602\n",
      "Epoch: 0, Loss:  0.6788308024406433\n",
      "Epoch: 0, Loss:  0.6815760135650635\n",
      "Epoch: 0, Loss:  0.7081987857818604\n",
      "Epoch: 0, Loss:  0.6805128455162048\n",
      "Epoch: 0, Loss:  0.6521236896514893\n",
      "Epoch: 0, Loss:  0.6766595840454102\n",
      "Epoch: 0, Loss:  0.7121343612670898\n",
      "Epoch: 0, Loss:  0.6428523659706116\n",
      "Epoch: 0, Loss:  0.7885184288024902\n",
      "Epoch: 0, Loss:  0.6914066672325134\n",
      "Epoch: 0, Loss:  0.6608184576034546\n",
      "Epoch: 0, Loss:  0.5883747339248657\n",
      "Epoch: 0, Loss:  0.7024860978126526\n",
      "Epoch: 0, Loss:  0.7218632698059082\n",
      "Epoch: 0, Loss:  0.604122519493103\n",
      "Epoch: 0, Loss:  0.6522314548492432\n",
      "Epoch: 0, Loss:  0.6958671808242798\n",
      "Epoch: 0, Loss:  0.6959032416343689\n",
      "Epoch: 0, Loss:  0.5575212240219116\n",
      "Epoch: 0, Loss:  0.6007604598999023\n",
      "Epoch: 0, Loss:  0.5069789886474609\n",
      "Epoch: 0, Loss:  0.5104523301124573\n",
      "Epoch: 0, Loss:  0.6199134588241577\n",
      "Epoch: 0, Loss:  0.6026194095611572\n",
      "Epoch: 0, Loss:  0.572900652885437\n",
      "Epoch: 0, Loss:  0.6483360528945923\n",
      "Epoch: 0, Loss:  0.5530642867088318\n",
      "Epoch: 0, Loss:  0.5230002999305725\n",
      "Epoch: 0, Loss:  0.5523337125778198\n",
      "Epoch: 0, Loss:  0.6820851564407349\n",
      "Epoch: 0, Loss:  0.7231471538543701\n",
      "Epoch: 0, Loss:  0.6001450419425964\n",
      "Epoch: 0, Loss:  0.6442132592201233\n",
      "Epoch: 0, Loss:  0.5845751762390137\n",
      "Epoch: 0, Loss:  0.5538822412490845\n",
      "Epoch: 0, Loss:  0.7229973077774048\n",
      "Epoch: 0, Loss:  0.6481303572654724\n",
      "Epoch: 0, Loss:  0.5090547204017639\n",
      "Epoch: 0, Loss:  0.7679483294487\n",
      "Epoch: 0, Loss:  0.6020013093948364\n",
      "Epoch: 0, Loss:  0.7180553078651428\n",
      "Epoch: 0, Loss:  0.7600733041763306\n",
      "Epoch: 0, Loss:  0.5997337698936462\n",
      "Epoch: 0, Loss:  0.6582953929901123\n",
      "Epoch: 0, Loss:  0.6745702028274536\n",
      "Epoch: 0, Loss:  0.5979700088500977\n",
      "Epoch: 0, Loss:  0.5495023727416992\n",
      "Epoch: 0, Loss:  0.599983811378479\n",
      "Epoch: 0, Loss:  0.647250771522522\n",
      "Epoch: 0, Loss:  0.6940884590148926\n",
      "Epoch: 0, Loss:  0.6342718601226807\n",
      "Epoch: 0, Loss:  0.799729585647583\n",
      "Epoch: 0, Loss:  0.629198431968689\n",
      "Epoch: 0, Loss:  0.6286988854408264\n",
      "Epoch: 0, Loss:  0.5511710047721863\n",
      "Epoch: 0, Loss:  0.504177987575531\n",
      "Epoch: 0, Loss:  0.6012246608734131\n",
      "Epoch: 0, Loss:  0.40994662046432495\n",
      "Epoch: 0, Loss:  0.5351983904838562\n",
      "Epoch: 0, Loss:  0.5845943093299866\n",
      "Epoch: 0, Loss:  0.6058567762374878\n",
      "Epoch: 0, Loss:  0.7235860824584961\n",
      "Epoch: 0, Loss:  0.6756539940834045\n",
      "Epoch: 0, Loss:  0.5989947319030762\n",
      "Epoch: 0, Loss:  0.585132896900177\n",
      "Epoch: 0, Loss:  0.5512560606002808\n",
      "Epoch: 0, Loss:  0.7225003242492676\n",
      "Epoch: 0, Loss:  0.7231715321540833\n",
      "Epoch: 1, Loss:  0.6938432455062866\n",
      "Epoch: 1, Loss:  0.5987555980682373\n",
      "Epoch: 1, Loss:  0.5990708470344543\n",
      "Epoch: 1, Loss:  0.540747344493866\n",
      "Epoch: 1, Loss:  0.6937458515167236\n",
      "Epoch: 1, Loss:  0.5987398624420166\n",
      "Epoch: 1, Loss:  0.5515027642250061\n",
      "Epoch: 1, Loss:  0.5988935828208923\n",
      "Epoch: 1, Loss:  0.6569324135780334\n",
      "Epoch: 1, Loss:  0.598687469959259\n",
      "Epoch: 1, Loss:  0.5509961843490601\n",
      "Epoch: 1, Loss:  0.6275720596313477\n",
      "Epoch: 1, Loss:  0.60104900598526\n",
      "Epoch: 1, Loss:  0.7681469917297363\n",
      "Epoch: 1, Loss:  0.6938987970352173\n",
      "Epoch: 1, Loss:  0.5037118196487427\n",
      "Epoch: 1, Loss:  0.7362420558929443\n",
      "Epoch: 1, Loss:  0.6937949657440186\n",
      "Epoch: 1, Loss:  0.5335386395454407\n",
      "Epoch: 1, Loss:  0.7236112952232361\n",
      "Epoch: 1, Loss:  0.5807462334632874\n",
      "Epoch: 1, Loss:  0.5815930366516113\n",
      "Epoch: 1, Loss:  0.6288210153579712\n",
      "Epoch: 1, Loss:  0.7529250383377075\n",
      "Epoch: 1, Loss:  0.693760871887207\n",
      "Epoch: 1, Loss:  0.6419405937194824\n",
      "Epoch: 1, Loss:  0.6061699986457825\n",
      "Epoch: 1, Loss:  0.5513186454772949\n",
      "Epoch: 1, Loss:  0.6287616491317749\n",
      "Epoch: 1, Loss:  0.6282441020011902\n",
      "Epoch: 1, Loss:  0.6466463804244995\n",
      "Epoch: 1, Loss:  0.599005937576294\n",
      "Epoch: 1, Loss:  0.6936215758323669\n",
      "Epoch: 1, Loss:  0.6282579898834229\n",
      "Epoch: 1, Loss:  0.693199098110199\n",
      "Epoch: 1, Loss:  0.7706954479217529\n",
      "Epoch: 1, Loss:  0.6759312152862549\n",
      "Epoch: 1, Loss:  0.5984838008880615\n",
      "Epoch: 1, Loss:  0.5511077046394348\n",
      "Epoch: 1, Loss:  0.6759141683578491\n",
      "Epoch: 1, Loss:  0.5994978547096252\n",
      "Epoch: 1, Loss:  0.6935497522354126\n",
      "Epoch: 1, Loss:  0.5510319471359253\n",
      "Epoch: 1, Loss:  0.5984789133071899\n",
      "Epoch: 1, Loss:  0.7064728736877441\n",
      "Epoch: 1, Loss:  0.7306764125823975\n",
      "Epoch: 1, Loss:  0.5157074928283691\n",
      "Epoch: 1, Loss:  0.60554438829422\n",
      "Epoch: 1, Loss:  0.6933335065841675\n",
      "Epoch: 1, Loss:  0.5545550584793091\n",
      "Epoch: 1, Loss:  0.6456608772277832\n",
      "Epoch: 1, Loss:  0.6461106538772583\n",
      "Epoch: 1, Loss:  0.5514411330223083\n",
      "Epoch: 1, Loss:  0.6461713314056396\n",
      "Epoch: 1, Loss:  0.5340942740440369\n",
      "Epoch: 1, Loss:  0.5988669395446777\n",
      "Epoch: 1, Loss:  0.6458745002746582\n",
      "Epoch: 1, Loss:  0.7233169078826904\n",
      "Epoch: 1, Loss:  0.5989373922348022\n",
      "Epoch: 1, Loss:  0.6459642648696899\n",
      "Epoch: 1, Loss:  0.5036811828613281\n",
      "Epoch: 1, Loss:  0.7710350751876831\n",
      "Epoch: 1, Loss:  0.8485356569290161\n",
      "Epoch: 1, Loss:  0.6759728193283081\n",
      "Epoch: 1, Loss:  0.6262190937995911\n",
      "Epoch: 1, Loss:  0.5983022451400757\n",
      "Epoch: 1, Loss:  0.7193782329559326\n",
      "Epoch: 1, Loss:  0.5985000133514404\n",
      "Epoch: 1, Loss:  0.5387105345726013\n",
      "Epoch: 1, Loss:  0.6937053203582764\n",
      "Epoch: 1, Loss:  0.6418266296386719\n",
      "Epoch: 1, Loss:  0.8004690408706665\n",
      "Epoch: 1, Loss:  0.6456563472747803\n",
      "Epoch: 1, Loss:  0.4573606252670288\n",
      "Epoch: 1, Loss:  0.5573337078094482\n",
      "Epoch: 1, Loss:  0.4855879843235016\n",
      "Epoch: 1, Loss:  0.6763654351234436\n",
      "Epoch: 2, Loss:  0.5509960055351257\n",
      "Epoch: 2, Loss:  0.5037622451782227\n",
      "Epoch: 2, Loss:  0.667158842086792\n",
      "Epoch: 2, Loss:  0.6492364406585693\n",
      "Epoch: 2, Loss:  0.5509116053581238\n",
      "Epoch: 2, Loss:  0.5020551681518555\n",
      "Epoch: 2, Loss:  0.5507683157920837\n",
      "Epoch: 2, Loss:  0.5983656644821167\n",
      "Epoch: 2, Loss:  0.5983191728591919\n",
      "Epoch: 2, Loss:  0.5983895063400269\n",
      "Epoch: 2, Loss:  0.4546576142311096\n",
      "Epoch: 2, Loss:  0.598412811756134\n",
      "Epoch: 2, Loss:  0.5983235836029053\n",
      "Epoch: 2, Loss:  0.45353591442108154\n",
      "Epoch: 2, Loss:  0.6058166027069092\n",
      "Epoch: 2, Loss:  0.6457805633544922\n",
      "Epoch: 2, Loss:  0.5986673831939697\n",
      "Epoch: 2, Loss:  0.675898551940918\n",
      "Epoch: 2, Loss:  0.5588562488555908\n",
      "Epoch: 2, Loss:  0.7534963488578796\n",
      "Epoch: 2, Loss:  0.4558766782283783\n",
      "Epoch: 2, Loss:  0.5508772730827332\n",
      "Epoch: 2, Loss:  0.6945096850395203\n",
      "Epoch: 2, Loss:  0.5514938831329346\n",
      "Epoch: 2, Loss:  0.5507979393005371\n",
      "Epoch: 2, Loss:  0.7233375906944275\n",
      "Epoch: 2, Loss:  0.7234207987785339\n",
      "Epoch: 2, Loss:  0.6090536117553711\n",
      "Epoch: 2, Loss:  0.5033657550811768\n",
      "Epoch: 2, Loss:  0.5807556509971619\n",
      "Epoch: 2, Loss:  0.5809751152992249\n",
      "Epoch: 2, Loss:  0.5509408712387085\n",
      "Epoch: 2, Loss:  0.6197887659072876\n",
      "Epoch: 2, Loss:  0.8482887744903564\n",
      "Epoch: 2, Loss:  0.5509976148605347\n",
      "Epoch: 2, Loss:  0.6461256146430969\n",
      "Epoch: 2, Loss:  0.6284193992614746\n",
      "Epoch: 2, Loss:  0.5509870052337646\n",
      "Epoch: 2, Loss:  0.5358178615570068\n",
      "Epoch: 2, Loss:  0.5034242868423462\n",
      "Epoch: 2, Loss:  0.5034033060073853\n",
      "Epoch: 2, Loss:  0.6456880569458008\n",
      "Epoch: 2, Loss:  0.7707586288452148\n",
      "Epoch: 2, Loss:  0.5981498956680298\n",
      "Epoch: 2, Loss:  0.598389744758606\n",
      "Epoch: 2, Loss:  0.5985665917396545\n",
      "Epoch: 2, Loss:  0.5508627891540527\n",
      "Epoch: 2, Loss:  0.5983495712280273\n",
      "Epoch: 2, Loss:  0.550987720489502\n",
      "Epoch: 2, Loss:  0.5998067855834961\n",
      "Epoch: 2, Loss:  0.5512372851371765\n",
      "Epoch: 2, Loss:  0.5983093976974487\n",
      "Epoch: 2, Loss:  0.5807454586029053\n",
      "Epoch: 2, Loss:  0.6758576035499573\n",
      "Epoch: 2, Loss:  0.5763037204742432\n",
      "Epoch: 2, Loss:  0.6767755746841431\n",
      "Epoch: 2, Loss:  0.5811824798583984\n",
      "Epoch: 2, Loss:  0.7484897375106812\n",
      "Epoch: 2, Loss:  0.6757903099060059\n",
      "Epoch: 2, Loss:  0.6282964944839478\n",
      "Epoch: 2, Loss:  0.6758180856704712\n",
      "Epoch: 2, Loss:  0.7232255339622498\n",
      "Epoch: 2, Loss:  0.5983988046646118\n",
      "Epoch: 2, Loss:  0.6056191325187683\n",
      "Epoch: 2, Loss:  0.675790548324585\n",
      "Epoch: 2, Loss:  0.6752556562423706\n",
      "Epoch: 2, Loss:  0.5982354283332825\n",
      "Epoch: 2, Loss:  0.605726957321167\n",
      "Epoch: 2, Loss:  0.6891545057296753\n",
      "Epoch: 2, Loss:  0.6612356305122375\n",
      "Epoch: 2, Loss:  0.4573413133621216\n",
      "Epoch: 2, Loss:  0.6498887538909912\n",
      "Epoch: 2, Loss:  0.6505540013313293\n",
      "Epoch: 2, Loss:  0.6505752801895142\n",
      "Epoch: 2, Loss:  0.5728558301925659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss:  0.6458032131195068\n",
      "Epoch: 2, Loss:  0.6764917969703674\n",
      "Epoch: 3, Loss:  0.551215648651123\n",
      "Epoch: 3, Loss:  0.5993900299072266\n",
      "Epoch: 3, Loss:  0.693276047706604\n",
      "Epoch: 3, Loss:  0.5992417335510254\n",
      "Epoch: 3, Loss:  0.645438551902771\n",
      "Epoch: 3, Loss:  0.5894656181335449\n",
      "Epoch: 3, Loss:  0.5969489812850952\n",
      "Epoch: 3, Loss:  0.6805853843688965\n",
      "Epoch: 3, Loss:  0.6284019947052002\n",
      "Epoch: 3, Loss:  0.7227641344070435\n",
      "Epoch: 3, Loss:  0.6076726913452148\n",
      "Epoch: 3, Loss:  0.5460940599441528\n",
      "Epoch: 3, Loss:  0.5436387062072754\n",
      "Epoch: 3, Loss:  0.5802454948425293\n",
      "Epoch: 3, Loss:  0.455913245677948\n",
      "Epoch: 3, Loss:  0.677978515625\n",
      "Epoch: 3, Loss:  0.6873284578323364\n",
      "Epoch: 3, Loss:  0.5146464705467224\n",
      "Epoch: 3, Loss:  0.5507365465164185\n",
      "Epoch: 3, Loss:  0.645881175994873\n",
      "Epoch: 3, Loss:  0.6475047469139099\n",
      "Epoch: 3, Loss:  0.6456055641174316\n",
      "Epoch: 3, Loss:  0.47887012362480164\n",
      "Epoch: 3, Loss:  0.604397177696228\n",
      "Epoch: 3, Loss:  0.6966629028320312\n",
      "Epoch: 3, Loss:  0.8008764982223511\n",
      "Epoch: 3, Loss:  0.6287802457809448\n",
      "Epoch: 3, Loss:  0.5984479188919067\n",
      "Epoch: 3, Loss:  0.5507574081420898\n",
      "Epoch: 3, Loss:  0.5983574390411377\n",
      "Epoch: 3, Loss:  0.59831702709198\n",
      "Epoch: 3, Loss:  0.5586985349655151\n",
      "Epoch: 3, Loss:  0.7232522964477539\n",
      "Epoch: 3, Loss:  0.5507319569587708\n",
      "Epoch: 3, Loss:  0.5507954359054565\n",
      "Epoch: 3, Loss:  0.5541819334030151\n",
      "Epoch: 3, Loss:  0.5982679128646851\n",
      "Epoch: 3, Loss:  0.5535281300544739\n",
      "Epoch: 3, Loss:  0.6457293033599854\n",
      "Epoch: 3, Loss:  0.6927890777587891\n",
      "Epoch: 3, Loss:  0.5982944965362549\n",
      "Epoch: 3, Loss:  0.5037930011749268\n",
      "Epoch: 3, Loss:  0.6027171015739441\n",
      "Epoch: 3, Loss:  0.557388961315155\n",
      "Epoch: 3, Loss:  0.6457461714744568\n",
      "Epoch: 3, Loss:  0.6757626533508301\n",
      "Epoch: 3, Loss:  0.6458089351654053\n",
      "Epoch: 3, Loss:  0.4557901918888092\n",
      "Epoch: 3, Loss:  0.6930853724479675\n",
      "Epoch: 3, Loss:  0.5983929634094238\n",
      "Epoch: 3, Loss:  0.645516574382782\n",
      "Epoch: 3, Loss:  0.5508134365081787\n",
      "Epoch: 3, Loss:  0.5982385873794556\n",
      "Epoch: 3, Loss:  0.6729373931884766\n",
      "Epoch: 3, Loss:  0.6457921266555786\n",
      "Epoch: 3, Loss:  0.6457324028015137\n",
      "Epoch: 3, Loss:  0.5983290076255798\n",
      "Epoch: 3, Loss:  0.5508495569229126\n",
      "Epoch: 3, Loss:  0.6457841992378235\n",
      "Epoch: 3, Loss:  0.5263252258300781\n",
      "Epoch: 3, Loss:  0.6454095840454102\n",
      "Epoch: 3, Loss:  0.6453953981399536\n",
      "Epoch: 3, Loss:  0.5983798503875732\n",
      "Epoch: 3, Loss:  0.5270216464996338\n",
      "Epoch: 3, Loss:  0.5507985353469849\n",
      "Epoch: 3, Loss:  0.5508733987808228\n",
      "Epoch: 3, Loss:  0.5508137941360474\n",
      "Epoch: 3, Loss:  0.5507215261459351\n",
      "Epoch: 3, Loss:  0.5807749032974243\n",
      "Epoch: 3, Loss:  0.5518736839294434\n",
      "Epoch: 3, Loss:  0.675795316696167\n",
      "Epoch: 3, Loss:  0.5981808304786682\n",
      "Epoch: 3, Loss:  0.5032699108123779\n",
      "Epoch: 3, Loss:  0.7232388257980347\n",
      "Epoch: 3, Loss:  0.5507433414459229\n",
      "Epoch: 3, Loss:  0.5032956004142761\n",
      "Epoch: 3, Loss:  0.5619745254516602\n",
      "Epoch: 4, Loss:  0.6457322239875793\n",
      "Epoch: 4, Loss:  0.6283397078514099\n",
      "Epoch: 4, Loss:  0.6757591962814331\n",
      "Epoch: 4, Loss:  0.5983238220214844\n",
      "Epoch: 4, Loss:  0.5974293947219849\n",
      "Epoch: 4, Loss:  0.503253698348999\n",
      "Epoch: 4, Loss:  0.550801157951355\n",
      "Epoch: 4, Loss:  0.5507111549377441\n",
      "Epoch: 4, Loss:  0.6738290190696716\n",
      "Epoch: 4, Loss:  0.6468988656997681\n",
      "Epoch: 4, Loss:  0.7359226942062378\n",
      "Epoch: 4, Loss:  0.5038975477218628\n",
      "Epoch: 4, Loss:  0.693206250667572\n",
      "Epoch: 4, Loss:  0.6456809043884277\n",
      "Epoch: 4, Loss:  0.6932583451271057\n",
      "Epoch: 4, Loss:  0.6932247877120972\n",
      "Epoch: 4, Loss:  0.5983126163482666\n",
      "Epoch: 4, Loss:  0.6933274269104004\n",
      "Epoch: 4, Loss:  0.6458368301391602\n",
      "Epoch: 4, Loss:  0.5016044974327087\n",
      "Epoch: 4, Loss:  0.5981718301773071\n",
      "Epoch: 4, Loss:  0.5333595275878906\n",
      "Epoch: 4, Loss:  0.4859958291053772\n",
      "Epoch: 4, Loss:  0.5983749628067017\n",
      "Epoch: 4, Loss:  0.5511194467544556\n",
      "Epoch: 4, Loss:  0.6674869060516357\n",
      "Epoch: 4, Loss:  0.6756852865219116\n",
      "Epoch: 4, Loss:  0.6756381988525391\n",
      "Epoch: 4, Loss:  0.5032793879508972\n",
      "Epoch: 4, Loss:  0.5507793426513672\n",
      "Epoch: 4, Loss:  0.598282516002655\n",
      "Epoch: 4, Loss:  0.6282801628112793\n",
      "Epoch: 4, Loss:  0.5187716484069824\n",
      "Epoch: 4, Loss:  0.5508352518081665\n",
      "Epoch: 4, Loss:  0.6455399394035339\n",
      "Epoch: 4, Loss:  0.455905556678772\n",
      "Epoch: 4, Loss:  0.6949715614318848\n",
      "Epoch: 4, Loss:  0.645793080329895\n",
      "Epoch: 4, Loss:  0.6458654999732971\n",
      "Epoch: 4, Loss:  0.5033561587333679\n",
      "Epoch: 4, Loss:  0.6756590604782104\n",
      "Epoch: 4, Loss:  0.5508195757865906\n",
      "Epoch: 4, Loss:  0.5982863903045654\n",
      "Epoch: 4, Loss:  0.5982440114021301\n",
      "Epoch: 4, Loss:  0.6457666158676147\n",
      "Epoch: 4, Loss:  0.5035964846611023\n",
      "Epoch: 4, Loss:  0.6932774782180786\n",
      "Epoch: 4, Loss:  0.6932693123817444\n",
      "Epoch: 4, Loss:  0.62816321849823\n",
      "Epoch: 4, Loss:  0.5982986688613892\n",
      "Epoch: 4, Loss:  0.6457563638687134\n",
      "Epoch: 4, Loss:  0.58078533411026\n",
      "Epoch: 4, Loss:  0.5032589435577393\n",
      "Epoch: 4, Loss:  0.5959847569465637\n",
      "Epoch: 4, Loss:  0.6067696809768677\n",
      "Epoch: 4, Loss:  0.6932485103607178\n",
      "Epoch: 4, Loss:  0.5982347130775452\n",
      "Epoch: 4, Loss:  0.7365604639053345\n",
      "Epoch: 4, Loss:  0.6741608381271362\n",
      "Epoch: 4, Loss:  0.7191890478134155\n",
      "Epoch: 4, Loss:  0.6456507444381714\n",
      "Epoch: 4, Loss:  0.5983785390853882\n",
      "Epoch: 4, Loss:  0.5032049417495728\n",
      "Epoch: 4, Loss:  0.5981260538101196\n",
      "Epoch: 4, Loss:  0.6303386688232422\n",
      "Epoch: 4, Loss:  0.6456875801086426\n",
      "Epoch: 4, Loss:  0.7232679128646851\n",
      "Epoch: 4, Loss:  0.5660065412521362\n",
      "Epoch: 4, Loss:  0.5507807731628418\n",
      "Epoch: 4, Loss:  0.5982343554496765\n",
      "Epoch: 4, Loss:  0.5032622814178467\n",
      "Epoch: 4, Loss:  0.5982341766357422\n",
      "Epoch: 4, Loss:  0.5981983542442322\n",
      "Epoch: 4, Loss:  0.6281473636627197\n",
      "Epoch: 4, Loss:  0.5507586002349854\n",
      "Epoch: 4, Loss:  0.5073429346084595\n",
      "Epoch: 4, Loss:  0.6827945113182068\n",
      "Epoch: 5, Loss:  0.6757371425628662\n",
      "Epoch: 5, Loss:  0.6457063555717468\n",
      "Epoch: 5, Loss:  0.598232626914978\n",
      "Epoch: 5, Loss:  0.5507373809814453\n",
      "Epoch: 5, Loss:  0.5982586741447449\n",
      "Epoch: 5, Loss:  0.6757432222366333\n",
      "Epoch: 5, Loss:  0.6584295034408569\n",
      "Epoch: 5, Loss:  0.7707197070121765\n",
      "Epoch: 5, Loss:  0.5982087254524231\n",
      "Epoch: 5, Loss:  0.5032275915145874\n",
      "Epoch: 5, Loss:  0.6757075786590576\n",
      "Epoch: 5, Loss:  0.5507649183273315\n",
      "Epoch: 5, Loss:  0.6457232236862183\n",
      "Epoch: 5, Loss:  0.6456447839736938\n",
      "Epoch: 5, Loss:  0.6757305264472961\n",
      "Epoch: 5, Loss:  0.7706756591796875\n",
      "Epoch: 5, Loss:  0.59825599193573\n",
      "Epoch: 5, Loss:  0.4082909822463989\n",
      "Epoch: 5, Loss:  0.7231941223144531\n",
      "Epoch: 5, Loss:  0.5982521772384644\n",
      "Epoch: 5, Loss:  0.5032284259796143\n",
      "Epoch: 5, Loss:  0.5982273817062378\n",
      "Epoch: 5, Loss:  0.550756573677063\n",
      "Epoch: 5, Loss:  0.5982286334037781\n",
      "Epoch: 5, Loss:  0.5982013940811157\n",
      "Epoch: 5, Loss:  0.64573073387146\n",
      "Epoch: 5, Loss:  0.5032210350036621\n",
      "Epoch: 5, Loss:  0.5507316589355469\n",
      "Epoch: 5, Loss:  0.5982325077056885\n",
      "Epoch: 5, Loss:  0.4082557260990143\n",
      "Epoch: 5, Loss:  0.6456694602966309\n",
      "Epoch: 5, Loss:  0.6282298564910889\n",
      "Epoch: 5, Loss:  0.5032655596733093\n",
      "Epoch: 5, Loss:  0.5982344150543213\n",
      "Epoch: 5, Loss:  0.5033226609230042\n",
      "Epoch: 5, Loss:  0.598207950592041\n",
      "Epoch: 5, Loss:  0.5982277393341064\n",
      "Epoch: 5, Loss:  0.5507054924964905\n",
      "Epoch: 5, Loss:  0.5510246753692627\n",
      "Epoch: 5, Loss:  0.5740764737129211\n",
      "Epoch: 5, Loss:  0.5032594203948975\n",
      "Epoch: 5, Loss:  0.5507283210754395\n",
      "Epoch: 5, Loss:  0.6757581233978271\n",
      "Epoch: 5, Loss:  0.5032289028167725\n",
      "Epoch: 5, Loss:  0.6456511616706848\n",
      "Epoch: 5, Loss:  0.5507875084877014\n",
      "Epoch: 5, Loss:  0.4082642197608948\n",
      "Epoch: 5, Loss:  0.5807385444641113\n",
      "Epoch: 5, Loss:  0.5032817125320435\n",
      "Epoch: 5, Loss:  0.7552798986434937\n",
      "Epoch: 5, Loss:  0.5982306003570557\n",
      "Epoch: 5, Loss:  0.5033239126205444\n",
      "Epoch: 5, Loss:  0.6282503604888916\n",
      "Epoch: 5, Loss:  0.5815855264663696\n",
      "Epoch: 5, Loss:  0.5982426404953003\n",
      "Epoch: 5, Loss:  0.5032401084899902\n",
      "Epoch: 5, Loss:  0.580691933631897\n",
      "Epoch: 5, Loss:  0.5507570505142212\n",
      "Epoch: 5, Loss:  0.5507416725158691\n",
      "Epoch: 5, Loss:  0.5982375144958496\n",
      "Epoch: 5, Loss:  0.5982314348220825\n",
      "Epoch: 5, Loss:  0.4557826519012451\n",
      "Epoch: 5, Loss:  0.5037490129470825\n",
      "Epoch: 5, Loss:  0.6456974744796753\n",
      "Epoch: 5, Loss:  0.6281992197036743\n",
      "Epoch: 5, Loss:  0.5045742392539978\n",
      "Epoch: 5, Loss:  0.5507149696350098\n",
      "Epoch: 5, Loss:  0.6457444429397583\n",
      "Epoch: 5, Loss:  0.5032325387001038\n",
      "Epoch: 5, Loss:  0.6282377243041992\n",
      "Epoch: 5, Loss:  0.6281962394714355\n",
      "Epoch: 5, Loss:  0.6932250261306763\n",
      "Epoch: 5, Loss:  0.5032404661178589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss:  0.6457224488258362\n",
      "Epoch: 5, Loss:  0.5520702600479126\n",
      "Epoch: 5, Loss:  0.6457036733627319\n",
      "Epoch: 5, Loss:  0.5982178449630737\n",
      "Epoch: 6, Loss:  0.5984547138214111\n",
      "Epoch: 6, Loss:  0.6932156682014465\n",
      "Epoch: 6, Loss:  0.6931636333465576\n",
      "Epoch: 6, Loss:  0.5137812495231628\n",
      "Epoch: 6, Loss:  0.6456676125526428\n",
      "Epoch: 6, Loss:  0.6931978464126587\n",
      "Epoch: 6, Loss:  0.6325608491897583\n",
      "Epoch: 6, Loss:  0.6456874012947083\n",
      "Epoch: 6, Loss:  0.5339157581329346\n",
      "Epoch: 6, Loss:  0.6457733511924744\n",
      "Epoch: 6, Loss:  0.5032285451889038\n",
      "Epoch: 6, Loss:  0.550692081451416\n",
      "Epoch: 6, Loss:  0.40828582644462585\n",
      "Epoch: 6, Loss:  0.5982277393341064\n",
      "Epoch: 6, Loss:  0.5981940031051636\n",
      "Epoch: 6, Loss:  0.6457140445709229\n",
      "Epoch: 6, Loss:  0.5032418966293335\n",
      "Epoch: 6, Loss:  0.5981634259223938\n",
      "Epoch: 6, Loss:  0.7233031392097473\n",
      "Epoch: 6, Loss:  0.5982447266578674\n",
      "Epoch: 6, Loss:  0.5507102012634277\n",
      "Epoch: 6, Loss:  0.6730276346206665\n",
      "Epoch: 6, Loss:  0.5507150888442993\n",
      "Epoch: 6, Loss:  0.5981934070587158\n",
      "Epoch: 6, Loss:  0.6456701755523682\n",
      "Epoch: 6, Loss:  0.6858503818511963\n",
      "Epoch: 6, Loss:  0.5981857776641846\n",
      "Epoch: 6, Loss:  0.5982834100723267\n",
      "Epoch: 6, Loss:  0.6689054369926453\n",
      "Epoch: 6, Loss:  0.675696849822998\n",
      "Epoch: 6, Loss:  0.5507362484931946\n",
      "Epoch: 6, Loss:  0.5509033203125\n",
      "Epoch: 6, Loss:  0.5509079098701477\n",
      "Epoch: 6, Loss:  0.5332531332969666\n",
      "Epoch: 6, Loss:  0.6457607746124268\n",
      "Epoch: 6, Loss:  0.5098937153816223\n",
      "Epoch: 6, Loss:  0.8006928563117981\n",
      "Epoch: 6, Loss:  0.5033890604972839\n",
      "Epoch: 6, Loss:  0.7412604689598083\n",
      "Epoch: 6, Loss:  0.5523297786712646\n",
      "Epoch: 6, Loss:  0.5204967856407166\n",
      "Epoch: 6, Loss:  0.5807716846466064\n",
      "Epoch: 6, Loss:  0.598264753818512\n",
      "Epoch: 6, Loss:  0.503305196762085\n",
      "Epoch: 6, Loss:  0.5981884002685547\n",
      "Epoch: 6, Loss:  0.5982421636581421\n",
      "Epoch: 6, Loss:  0.7232409715652466\n",
      "Epoch: 6, Loss:  0.4557586908340454\n",
      "Epoch: 6, Loss:  0.6457203030586243\n",
      "Epoch: 6, Loss:  0.5807533860206604\n",
      "Epoch: 6, Loss:  0.7450466156005859\n",
      "Epoch: 6, Loss:  0.5332907438278198\n",
      "Epoch: 6, Loss:  0.5982199907302856\n",
      "Epoch: 6, Loss:  0.5968806147575378\n",
      "Epoch: 6, Loss:  0.6759727001190186\n",
      "Epoch: 6, Loss:  0.6457149982452393\n",
      "Epoch: 6, Loss:  0.5979848504066467\n",
      "Epoch: 6, Loss:  0.7015363574028015\n",
      "Epoch: 6, Loss:  0.6756811141967773\n",
      "Epoch: 6, Loss:  0.6457148194313049\n",
      "Epoch: 6, Loss:  0.7263901829719543\n",
      "Epoch: 6, Loss:  0.4760383367538452\n",
      "Epoch: 6, Loss:  0.5507387518882751\n",
      "Epoch: 6, Loss:  0.5507409572601318\n",
      "Epoch: 6, Loss:  0.5507213473320007\n",
      "Epoch: 6, Loss:  0.5032415390014648\n",
      "Epoch: 6, Loss:  0.6282438039779663\n",
      "Epoch: 6, Loss:  0.7754433751106262\n",
      "Epoch: 6, Loss:  0.5507338047027588\n",
      "Epoch: 6, Loss:  0.645717442035675\n",
      "Epoch: 6, Loss:  0.5788617134094238\n",
      "Epoch: 6, Loss:  0.5506942868232727\n",
      "Epoch: 6, Loss:  0.5982363224029541\n",
      "Epoch: 6, Loss:  0.598217785358429\n",
      "Epoch: 6, Loss:  0.7232039570808411\n",
      "Epoch: 6, Loss:  0.5499064922332764\n",
      "Epoch: 6, Loss:  0.5935115814208984\n",
      "Epoch: 7, Loss:  0.59822678565979\n",
      "Epoch: 7, Loss:  0.503227949142456\n",
      "Epoch: 7, Loss:  0.5507025718688965\n",
      "Epoch: 7, Loss:  0.598268985748291\n",
      "Epoch: 7, Loss:  0.5521224737167358\n",
      "Epoch: 7, Loss:  0.5807492733001709\n",
      "Epoch: 7, Loss:  0.5807591676712036\n",
      "Epoch: 7, Loss:  0.5032126903533936\n",
      "Epoch: 7, Loss:  0.5507533550262451\n",
      "Epoch: 7, Loss:  0.4082525074481964\n",
      "Epoch: 7, Loss:  0.6689243316650391\n",
      "Epoch: 7, Loss:  0.5982428193092346\n",
      "Epoch: 7, Loss:  0.6757261753082275\n",
      "Epoch: 7, Loss:  0.5981680154800415\n",
      "Epoch: 7, Loss:  0.598228931427002\n",
      "Epoch: 7, Loss:  0.6769994497299194\n",
      "Epoch: 7, Loss:  0.6931938529014587\n",
      "Epoch: 7, Loss:  0.6457022428512573\n",
      "Epoch: 7, Loss:  0.4632660150527954\n",
      "Epoch: 7, Loss:  0.5507194995880127\n",
      "Epoch: 7, Loss:  0.5332536697387695\n",
      "Epoch: 7, Loss:  0.5033579468727112\n",
      "Epoch: 7, Loss:  0.6757180690765381\n",
      "Epoch: 7, Loss:  0.6856658458709717\n",
      "Epoch: 7, Loss:  0.6457167863845825\n",
      "Epoch: 7, Loss:  0.598202645778656\n",
      "Epoch: 7, Loss:  0.5958317518234253\n",
      "Epoch: 7, Loss:  0.5987305641174316\n",
      "Epoch: 7, Loss:  0.7134410738945007\n",
      "Epoch: 7, Loss:  0.5538371801376343\n",
      "Epoch: 7, Loss:  0.6873068809509277\n",
      "Epoch: 7, Loss:  0.5982198119163513\n",
      "Epoch: 7, Loss:  0.6457239389419556\n",
      "Epoch: 7, Loss:  0.5688707232475281\n",
      "Epoch: 7, Loss:  0.4082717299461365\n",
      "Epoch: 7, Loss:  0.5507141351699829\n",
      "Epoch: 7, Loss:  0.5032325983047485\n",
      "Epoch: 7, Loss:  0.5032203197479248\n",
      "Epoch: 7, Loss:  0.6127044558525085\n",
      "Epoch: 7, Loss:  0.6456990242004395\n",
      "Epoch: 7, Loss:  0.5507394075393677\n",
      "Epoch: 7, Loss:  0.6282139420509338\n",
      "Epoch: 7, Loss:  0.723204493522644\n",
      "Epoch: 7, Loss:  0.6457164287567139\n",
      "Epoch: 7, Loss:  0.5982179641723633\n",
      "Epoch: 7, Loss:  0.5982073545455933\n",
      "Epoch: 7, Loss:  0.5507383346557617\n",
      "Epoch: 7, Loss:  0.6931442618370056\n",
      "Epoch: 7, Loss:  0.6969828605651855\n",
      "Epoch: 7, Loss:  0.5032360553741455\n",
      "Epoch: 7, Loss:  0.5982345342636108\n",
      "Epoch: 7, Loss:  0.5981972813606262\n",
      "Epoch: 7, Loss:  0.5981999635696411\n",
      "Epoch: 7, Loss:  0.5982241034507751\n",
      "Epoch: 7, Loss:  0.5559148788452148\n",
      "Epoch: 7, Loss:  0.6282221674919128\n",
      "Epoch: 7, Loss:  0.6281120181083679\n",
      "Epoch: 7, Loss:  0.5982308387756348\n",
      "Epoch: 7, Loss:  0.675693929195404\n",
      "Epoch: 7, Loss:  0.5562233924865723\n",
      "Epoch: 7, Loss:  0.6756998300552368\n",
      "Epoch: 7, Loss:  0.6456822156906128\n",
      "Epoch: 7, Loss:  0.5507239103317261\n",
      "Epoch: 7, Loss:  0.6931522488594055\n",
      "Epoch: 7, Loss:  0.6191626191139221\n",
      "Epoch: 7, Loss:  0.5507174730300903\n",
      "Epoch: 7, Loss:  0.5032334327697754\n",
      "Epoch: 7, Loss:  0.4082551598548889\n",
      "Epoch: 7, Loss:  0.5982051491737366\n",
      "Epoch: 7, Loss:  0.6282138824462891\n",
      "Epoch: 7, Loss:  0.5982075929641724\n",
      "Epoch: 7, Loss:  0.5981987118721008\n",
      "Epoch: 7, Loss:  0.5032175183296204\n",
      "Epoch: 7, Loss:  0.6456942558288574\n",
      "Epoch: 7, Loss:  0.5507125854492188\n",
      "Epoch: 7, Loss:  0.5506381392478943\n",
      "Epoch: 7, Loss:  0.5507231950759888\n",
      "Epoch: 8, Loss:  0.503233790397644\n",
      "Epoch: 8, Loss:  0.47803664207458496\n",
      "Epoch: 8, Loss:  0.6757042407989502\n",
      "Epoch: 8, Loss:  0.5982069969177246\n",
      "Epoch: 8, Loss:  0.5506868362426758\n",
      "Epoch: 8, Loss:  0.5981884002685547\n",
      "Epoch: 8, Loss:  0.550717294216156\n",
      "Epoch: 8, Loss:  0.5981969833374023\n",
      "Epoch: 8, Loss:  0.5507068037986755\n",
      "Epoch: 8, Loss:  0.455750972032547\n",
      "Epoch: 8, Loss:  0.5507171154022217\n",
      "Epoch: 8, Loss:  0.5981930494308472\n",
      "Epoch: 8, Loss:  0.6756991744041443\n",
      "Epoch: 8, Loss:  0.633430004119873\n",
      "Epoch: 8, Loss:  0.5032321810722351\n",
      "Epoch: 8, Loss:  0.5507166981697083\n",
      "Epoch: 8, Loss:  0.6419333219528198\n",
      "Epoch: 8, Loss:  0.5507701635360718\n",
      "Epoch: 8, Loss:  0.598210334777832\n",
      "Epoch: 8, Loss:  0.6456966996192932\n",
      "Epoch: 8, Loss:  0.550717830657959\n",
      "Epoch: 8, Loss:  0.5442701578140259\n",
      "Epoch: 8, Loss:  0.5507087707519531\n",
      "Epoch: 8, Loss:  0.5032480955123901\n",
      "Epoch: 8, Loss:  0.5507042407989502\n",
      "Epoch: 8, Loss:  0.6931734085083008\n",
      "Epoch: 8, Loss:  0.6931663751602173\n",
      "Epoch: 8, Loss:  0.645671010017395\n",
      "Epoch: 8, Loss:  0.5507025718688965\n",
      "Epoch: 8, Loss:  0.5507246255874634\n",
      "Epoch: 8, Loss:  0.5507210493087769\n",
      "Epoch: 8, Loss:  0.5981988906860352\n",
      "Epoch: 8, Loss:  0.6456787586212158\n",
      "Epoch: 8, Loss:  0.5981869101524353\n",
      "Epoch: 8, Loss:  0.5981913805007935\n",
      "Epoch: 8, Loss:  0.550714910030365\n",
      "Epoch: 8, Loss:  0.5032352209091187\n",
      "Epoch: 8, Loss:  0.6757082343101501\n",
      "Epoch: 8, Loss:  0.5982068181037903\n",
      "Epoch: 8, Loss:  0.5982062220573425\n",
      "Epoch: 8, Loss:  0.72319495677948\n",
      "Epoch: 8, Loss:  0.6456732153892517\n",
      "Epoch: 8, Loss:  0.5507041215896606\n",
      "Epoch: 8, Loss:  0.6456773281097412\n",
      "Epoch: 8, Loss:  0.5981974601745605\n",
      "Epoch: 8, Loss:  0.6757109761238098\n",
      "Epoch: 8, Loss:  0.6456552743911743\n",
      "Epoch: 8, Loss:  0.8481550216674805\n",
      "Epoch: 8, Loss:  0.5981984734535217\n",
      "Epoch: 8, Loss:  0.5032293796539307\n",
      "Epoch: 8, Loss:  0.5507053732872009\n",
      "Epoch: 8, Loss:  0.645799994468689\n",
      "Epoch: 8, Loss:  0.7232035398483276\n",
      "Epoch: 8, Loss:  0.5981712341308594\n",
      "Epoch: 8, Loss:  0.5032256841659546\n",
      "Epoch: 8, Loss:  0.553917407989502\n",
      "Epoch: 8, Loss:  0.6757074594497681\n",
      "Epoch: 8, Loss:  0.7531962394714355\n",
      "Epoch: 8, Loss:  0.5507110357284546\n",
      "Epoch: 8, Loss:  0.5507075786590576\n",
      "Epoch: 8, Loss:  0.5507138967514038\n",
      "Epoch: 8, Loss:  0.6757004261016846\n",
      "Epoch: 8, Loss:  0.5507093071937561\n",
      "Epoch: 8, Loss:  0.598213791847229\n",
      "Epoch: 8, Loss:  0.7231902480125427\n",
      "Epoch: 8, Loss:  0.877685546875\n",
      "Epoch: 8, Loss:  0.598196268081665\n",
      "Epoch: 8, Loss:  0.5981850028038025\n",
      "Epoch: 8, Loss:  0.6024789810180664\n",
      "Epoch: 8, Loss:  0.5507146120071411\n",
      "Epoch: 8, Loss:  0.5981887578964233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss:  0.5981893539428711\n",
      "Epoch: 8, Loss:  0.5981979370117188\n",
      "Epoch: 8, Loss:  0.5981832146644592\n",
      "Epoch: 8, Loss:  0.503242015838623\n",
      "Epoch: 8, Loss:  0.6282283663749695\n",
      "Epoch: 8, Loss:  0.4082384705543518\n",
      "Epoch: 9, Loss:  0.5032060146331787\n",
      "Epoch: 9, Loss:  0.5507051944732666\n",
      "Epoch: 9, Loss:  0.6282150745391846\n",
      "Epoch: 9, Loss:  0.7231869101524353\n",
      "Epoch: 9, Loss:  0.6058155298233032\n",
      "Epoch: 9, Loss:  0.7231874465942383\n",
      "Epoch: 9, Loss:  0.5032271146774292\n",
      "Epoch: 9, Loss:  0.6456894874572754\n",
      "Epoch: 9, Loss:  0.6456913948059082\n",
      "Epoch: 9, Loss:  0.4557192027568817\n",
      "Epoch: 9, Loss:  0.6121832728385925\n",
      "Epoch: 9, Loss:  0.6456859111785889\n",
      "Epoch: 9, Loss:  0.6456760168075562\n",
      "Epoch: 9, Loss:  0.6539126634597778\n",
      "Epoch: 9, Loss:  0.5507179498672485\n",
      "Epoch: 9, Loss:  0.4082601070404053\n",
      "Epoch: 9, Loss:  0.5982562303543091\n",
      "Epoch: 9, Loss:  0.5984361171722412\n",
      "Epoch: 9, Loss:  0.6460344791412354\n",
      "Epoch: 9, Loss:  0.7144325971603394\n",
      "Epoch: 9, Loss:  0.675715982913971\n",
      "Epoch: 9, Loss:  0.598230242729187\n",
      "Epoch: 9, Loss:  0.6456942558288574\n",
      "Epoch: 9, Loss:  0.5531141757965088\n",
      "Epoch: 9, Loss:  0.8007024526596069\n",
      "Epoch: 9, Loss:  0.550717294216156\n",
      "Epoch: 9, Loss:  0.6433539986610413\n",
      "Epoch: 9, Loss:  0.6458627581596375\n",
      "Epoch: 9, Loss:  0.6931641101837158\n",
      "Epoch: 9, Loss:  0.6456793546676636\n",
      "Epoch: 9, Loss:  0.5807405710220337\n",
      "Epoch: 9, Loss:  0.6932111978530884\n",
      "Epoch: 9, Loss:  0.4557521939277649\n",
      "Epoch: 9, Loss:  0.5531525611877441\n",
      "Epoch: 9, Loss:  0.37052738666534424\n",
      "Epoch: 9, Loss:  0.6931244134902954\n",
      "Epoch: 9, Loss:  0.5982239246368408\n",
      "Epoch: 9, Loss:  0.6931953430175781\n",
      "Epoch: 9, Loss:  0.6029155254364014\n",
      "Epoch: 9, Loss:  0.6456847190856934\n",
      "Epoch: 9, Loss:  0.6456789374351501\n",
      "Epoch: 9, Loss:  0.5507031679153442\n",
      "Epoch: 9, Loss:  0.580745279788971\n",
      "Epoch: 9, Loss:  0.6271553039550781\n",
      "Epoch: 9, Loss:  0.5807266235351562\n",
      "Epoch: 9, Loss:  0.6058025360107422\n",
      "Epoch: 9, Loss:  0.5982105731964111\n",
      "Epoch: 9, Loss:  0.5982089042663574\n",
      "Epoch: 9, Loss:  0.5032213926315308\n",
      "Epoch: 9, Loss:  0.6756923198699951\n",
      "Epoch: 9, Loss:  0.5507291555404663\n",
      "Epoch: 9, Loss:  0.5982030630111694\n",
      "Epoch: 9, Loss:  0.5981991291046143\n",
      "Epoch: 9, Loss:  0.5507326126098633\n",
      "Epoch: 9, Loss:  0.5982045531272888\n",
      "Epoch: 9, Loss:  0.6898919343948364\n",
      "Epoch: 9, Loss:  0.6746546030044556\n",
      "Epoch: 9, Loss:  0.5837178230285645\n",
      "Epoch: 9, Loss:  0.5982201099395752\n",
      "Epoch: 9, Loss:  0.5982323884963989\n",
      "Epoch: 9, Loss:  0.4557279348373413\n",
      "Epoch: 9, Loss:  0.6456811428070068\n",
      "Epoch: 9, Loss:  0.653339147567749\n",
      "Epoch: 9, Loss:  0.5507236123085022\n",
      "Epoch: 9, Loss:  0.723189115524292\n",
      "Epoch: 9, Loss:  0.6756923198699951\n",
      "Epoch: 9, Loss:  0.5982053875923157\n",
      "Epoch: 9, Loss:  0.5507118701934814\n",
      "Epoch: 9, Loss:  0.5981996059417725\n",
      "Epoch: 9, Loss:  0.6282241344451904\n",
      "Epoch: 9, Loss:  0.6282311677932739\n",
      "Epoch: 9, Loss:  0.5507230162620544\n",
      "Epoch: 9, Loss:  0.6757087707519531\n",
      "Epoch: 9, Loss:  0.5507066249847412\n",
      "Epoch: 9, Loss:  0.6282133460044861\n",
      "Epoch: 9, Loss:  0.8007123470306396\n",
      "Epoch: 9, Loss:  0.45573750138282776\n"
     ]
    }
   ],
   "source": [
    "#for training\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\n",
    "\n",
    "\n",
    "#Save PATH\n",
    "PATH = r\"C:\\Users\\jethr\\OneDrive\\Documents\\Kaggle\\NLPTweets\\model.pt\"\n",
    "\n",
    "# for loading Saved model\n",
    "#model = torch.load(PATH)\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "# Save trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.float)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 0.43204202232435984\n",
      "F1 Score (Micro) = 0.43204202232435984\n",
      "F1 Score (Macro) = 0.3016964695093994\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    outputs, targets = validation(epoch)\n",
    "    outputs = np.array(outputs) >= 0.5\n",
    "    accuracy = metrics.accuracy_score(targets, outputs)\n",
    "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "    print(f\"Accuracy Score = {accuracy}\")\n",
    "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "l1.embeddings.position_ids \t torch.Size([1, 512])\n",
      "l1.embeddings.word_embeddings.weight \t torch.Size([30522, 768])\n",
      "l1.embeddings.position_embeddings.weight \t torch.Size([512, 768])\n",
      "l1.embeddings.token_type_embeddings.weight \t torch.Size([2, 768])\n",
      "l1.embeddings.LayerNorm.weight \t torch.Size([768])\n",
      "l1.embeddings.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.0.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.0.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.0.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.0.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.0.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.0.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.0.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.0.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.0.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.0.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.0.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.0.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.0.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.0.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.0.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.0.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.1.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.1.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.1.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.1.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.1.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.1.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.1.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.1.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.1.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.1.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.1.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.1.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.1.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.1.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.1.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.1.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.2.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.2.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.2.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.2.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.2.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.2.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.2.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.2.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.2.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.2.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.2.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.2.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.2.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.2.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.2.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.2.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.3.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.3.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.3.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.3.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.3.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.3.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.3.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.3.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.3.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.3.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.3.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.3.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.3.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.3.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.3.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.3.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.4.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.4.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.4.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.4.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.4.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.4.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.4.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.4.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.4.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.4.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.4.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.4.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.4.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.4.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.4.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.4.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.5.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.5.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.5.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.5.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.5.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.5.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.5.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.5.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.5.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.5.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.5.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.5.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.5.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.5.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.5.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.5.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.6.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.6.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.6.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.6.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.6.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.6.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.6.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.6.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.6.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.6.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.6.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.6.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.6.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.6.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.6.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.6.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.7.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.7.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.7.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.7.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.7.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.7.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.7.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.7.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.7.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.7.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.7.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.7.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.7.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.7.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.7.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.7.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.8.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.8.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.8.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.8.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.8.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.8.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.8.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.8.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.8.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.8.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.8.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.8.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.8.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.8.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.8.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.8.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.9.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.9.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.9.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.9.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.9.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.9.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.9.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.9.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.9.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.9.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.9.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.9.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.9.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.9.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.9.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.9.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.10.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.10.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.10.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.10.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.10.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.10.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.10.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.10.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.10.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.10.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.10.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.10.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.10.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.10.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.10.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.10.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.11.attention.self.query.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.11.attention.self.query.bias \t torch.Size([768])\n",
      "l1.encoder.layer.11.attention.self.key.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.11.attention.self.key.bias \t torch.Size([768])\n",
      "l1.encoder.layer.11.attention.self.value.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.11.attention.self.value.bias \t torch.Size([768])\n",
      "l1.encoder.layer.11.attention.output.dense.weight \t torch.Size([768, 768])\n",
      "l1.encoder.layer.11.attention.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.11.attention.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.11.attention.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.encoder.layer.11.intermediate.dense.weight \t torch.Size([3072, 768])\n",
      "l1.encoder.layer.11.intermediate.dense.bias \t torch.Size([3072])\n",
      "l1.encoder.layer.11.output.dense.weight \t torch.Size([768, 3072])\n",
      "l1.encoder.layer.11.output.dense.bias \t torch.Size([768])\n",
      "l1.encoder.layer.11.output.LayerNorm.weight \t torch.Size([768])\n",
      "l1.encoder.layer.11.output.LayerNorm.bias \t torch.Size([768])\n",
      "l1.pooler.dense.weight \t torch.Size([768, 768])\n",
      "l1.pooler.dense.bias \t torch.Size([768])\n",
      "l3.weight \t torch.Size([20, 768])\n",
      "l3.bias \t torch.Size([20])\n",
      "l4.weight \t torch.Size([1, 20])\n",
      "l4.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction\n",
    "def predict(test_dataset,tokenizer,max_len,model):\n",
    "    tweet = str(test_dataset[\"tweet\"])\n",
    "    inputs = tokenizer.encode_plus(\n",
    "        tweet,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        pad_to_max_length=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    \n",
    "    #encode prediction dataset\n",
    "    predict_ids = torch.tensor(inputs['input_ids'],dtype=torch.long)\n",
    "    predict_mask = torch.tensor(inputs['attention_mask'],dtype=torch.long)\n",
    "    predict_token_type_ids = torch.tensor(inputs[\"token_type_ids\"],dtype=torch.long)\n",
    "    \n",
    "    print(predict_ids.shape)\n",
    "    \n",
    "    #forward pass\n",
    "    outputs = model(predict_ids, predict_mask, predict_token_type_ids)\n",
    "    \n",
    "    return outputs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jethr\\anaconda3\\envs\\ml\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "eval_data = CustomDataset(df_test, tokenizer, MAX_LEN,\"test\")\n",
    "eval_params = {'batch_size': 4,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "eval_loader = DataLoader(eval_data,**eval_params)\n",
    "model.eval()\n",
    "results = []\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for _,data in enumerate(eval_loader,0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)  \n",
    "            outputs = model(ids, mask, token_type_ids).tolist()\n",
    "            results.append(outputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_predictions = [item for sublist in results for item in sublist]\n",
    "df_predict = pd.DataFrame(flat_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Count'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check outputs\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.histplot(df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.392277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.488333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  3263.000000\n",
       "mean      0.392277\n",
       "std       0.488333\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set threshold\n",
    "df_predict[df_predict>=0.5] = 1\n",
    "df_predict[df_predict< 0.5 ] = 0\n",
    "df_predict.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating submission data.\n",
    "\n",
    "submission = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv')\n",
    "submission['target'] = df_predict\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
